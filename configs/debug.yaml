# debug mode on 2 multi-GPU training
# @package _global_
# Default configuration
defaults:
  - model: dino_v2
  - data@data.0: open_images_debug_1
  - data@data.1: open_images_debug_2
  - optimizer: adamw
  - scheduler: cosine
  - evaluation/data@evaluation.data.0: cub200
  - evaluation/data@evaluation.data.1: sun397
  - _self_

# Experiment settings
experiment_name: train_debug
seed: 42

# Training settings
training:
  num_epochs: 50
  batch_size: 256 # batch size per GPU (optimized for ViT-Small, 2 A100 GPUs)
  num_workers: 16
  pin_memory: true
  gradient_accumulation_steps: 1
  mixed_precision: true
  gradient_clip: 3.0
  prefetch_factor: 2  # Prefetch more batches (2x default) to keep GPU fed
  persistent_workers: true  # Keep workers alive between epochs

# Distributed training (default: enabled)
distributed:
  enabled: true         # Set to true when launching with torchrun on multiple GPUs
  backend: nccl
  init_method: env://
  find_unused_parameters: false

# Checkpointing
checkpoint:
  save_dir: ./checkpoints  # Base directory (experiment_name is appended)
  save_frequency: 1 # every n epochs
  resume_from: null  # null (fresh start) or full path to checkpoint from previous experiment

# change these config and 'evaluation.knn_eval_frequency' to debug early stopping
early_stopping:
  patience: 2
  min_delta: 0

# Logging
logging:
  log_dir: ./logs
  log_frequency: 5

# K-NN Evaluation
evaluation:
  batch_size: 256
  knn_eval_frequency: 1
  top_k_models: 5
  knn_k: 20
