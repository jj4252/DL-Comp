# Default configuration
defaults:
  - model: dino_v2
  - data: fall2025_deeplearning  # Main competition dataset
  - optimizer: adamw
  - scheduler: cosine
  - _self_

# Experiment settings
experiment_name: ssl_vision_training
seed: 42

# Training settings
training:
  num_epochs: 200
  batch_size: 128
  num_workers: 16
  pin_memory: true
  gradient_accumulation_steps: 1
  mixed_precision: true
  gradient_clip: 3.0
  prefetch_factor: 2  # Prefetch more batches (2x default) to keep GPU fed
  persistent_workers: true  # Keep workers alive between epochs

# Checkpointing
checkpoint:
  save_dir: /gpfs/data/fieremanslab/dayne/projects/DL-Final-Competition/checkpoints  # Base directory (experiment_name is appended)
  save_frequency: 5 # every n epochs
  resume_from: null  # Set to "auto" to auto-resume, or path for specific checkpoint
  auto_resume: true  # Automatically resume from latest checkpoint if exists

# Logging
logging:
  log_dir: ./logs
  log_frequency: 100

# Evaluation
evaluation:
  checkpoint_path: /gpfs/data/fieremanslab/dayne/projects/DL-Final-Competition/checkpoint_final.pth
  eval_dataset: cifar100  # Dataset to evaluate on
  eval_image_key: img  # 'img' for CIFAR, 'image' for most others
  batch_size: 256
  results_dir: ./eval_results

  # k-NN evaluation
  knn_k: 20

  # Linear probing
  linear_probe_epochs: 100
  linear_probe_lr: 0.001
