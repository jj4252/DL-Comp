# Default configuration
defaults:
  - model: dino_v2
  - data: fall2025_deeplearning  # Main competition dataset
  - optimizer: adamw
  - scheduler: cosine
  - _self_

# Experiment settings
experiment_name: ssl_vision_training
seed: 42

# Training settings
training:
  num_epochs: 200
  batch_size: 128
  num_workers: 16
  pin_memory: true
  gradient_accumulation_steps: 1
  mixed_precision: true
  gradient_clip: 3.0
  prefetch_factor: 2  # Prefetch more batches (2x default) to keep GPU fed
  persistent_workers: true  # Keep workers alive between epochs

# Checkpointing
checkpoint:
  save_dir: /gpfs/data/fieremanslab/dayne/projects/DL-Final-Competition/checkpoints  # Base directory (experiment_name is appended)
  save_frequency: 5 # every n epochs
  resume_from: null  # null (fresh start) or full path to checkpoint from previous experiment

# Logging
logging:
  log_dir: ./logs
  log_frequency: 100

# Evaluation
evaluation:
  checkpoint_path: null # not used during training, full path to checkpoint for evaluation
  batch_size: 256
  results_dir: ./eval_results

  # k-NN evaluation
  knn_k: 20

  # Linear probing
  linear_probe_epochs: 2000
  linear_probe_lr: 0.001
